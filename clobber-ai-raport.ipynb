{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sztuczna inteligencja i inżynieria wiedzy\n",
    "## Lista 2. - Implementacja AI do gry Clobber\n",
    "### Michał Maksanty (272685)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cel zadania\n",
    "Celem ćwiczenia jest praktyczne zapoznanie się z algorytmami grania w gry dwuosobowe - algorytmem Minimax oraz jego ulepszeniem z wykorzystaniem alfa-beta cięć."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Wprowadzenie teoretyczne\n",
    "### 2.1 Definicje\n",
    "- **Drzewo decyzyjne**: Skierowane drzewo, w którym każdy węzeł reprezentuje stan problemu, a krawędzie reprezentują działania prowadzące do kolejnych stanów.\n",
    "- **Gra o sumie zerowej**: Gra, w której suma wypłat wszystkich graczy wynosi zero w każdej możliwej kombinacji działań.\n",
    "\n",
    "### 2.2 Algorytm Minimax\n",
    "Strategia przeszukiwania drzewa gry służąca do podejmowania decyzji w grach dwuosobowych o sumie zerowej. Algorytm dąży do minimalizacji maksymalnej możliwej straty.\n",
    "\n",
    "### 2.3 Alfa-beta cięcie\n",
    "Optymalizacja algorytmu Minimax polegająca na eliminowaniu gałęzi drzewa, które z pewnością nie są optymalne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementacja podstawowych klas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższy kod implementuje grę planszową Clobber w języku Python (narazie bez żadnych funkcji AI - czysta gra). Rozgrywka toczy się na dwuwymiarowej planszy, gdzie pola są naprzemiennie wypełnione pionkami białymi i czarnymi. Gracze wykonują ruchy, „zbijając” sąsiednie pionki przeciwnika i zastępując je swoimi, a gra kończy się, gdy żaden pionek nie może wykonać kolejnego ruchu. Klasa Clobber zarządza planszą, stanem gry, bieżącym graczem i numerem rundy, a także udostępnia metodę move, umożliwiającą wykonanie ruchu w jednym z czterech kierunków. Enumy Pawn, GameStatus i Direction pomagają zarządzać logiką gry, zapewniając czytelność i bezpieczeństwo typów. Dodatkowo, gra umożliwia wizualizację planszy za pomocą metody print_board, opcjonalnie z nazwami pól.\n",
    "\n",
    "Ogólnie częśc z funkcjonalności tej klasy nie jest później wykorzystana, jednak klasa została utworzona całościowo w taki sposób, by z jej pomocą można było samemu rozegrać pełnoprawną rozgrywkę w Clobbera (człowiek vs człowiek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:45:48.318664Z",
     "start_time": "2025-05-29T20:45:48.284106Z"
    }
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import List\n",
    "\n",
    "class Pawn(Enum):\n",
    "    WHITE = 'W'\n",
    "    BLACK = 'B'\n",
    "    EMPTY = '_'\n",
    "    def __str__(self):\n",
    "        return self.value\n",
    "\n",
    "class GameStatus(Enum):\n",
    "    NOT_STARTED = 0\n",
    "    IN_PROGRESS = 1\n",
    "    ENDED = 2\n",
    "\n",
    "class Direction(Enum):\n",
    "    UP = 1\n",
    "    DOWN = 2\n",
    "    RIGHT = 3\n",
    "    LEFT = 4\n",
    "\n",
    "Board = List[List[Pawn]]\n",
    "\n",
    "class Clobber:\n",
    "    def __init__(self, n=5, m=6):\n",
    "        self._n = n\n",
    "        self._m = m\n",
    "        pawn = Pawn.WHITE if m % 2 == 0 else Pawn.BLACK\n",
    "        self._board = [[] for _ in range(m)]\n",
    "        for row in self._board:\n",
    "            for _ in range(n):\n",
    "                row.append(pawn)\n",
    "                pawn = self.other_player(pawn)\n",
    "        self._current_player = Pawn.WHITE\n",
    "        self._game_status = GameStatus.NOT_STARTED\n",
    "        self._rounds_nb = 0\n",
    "\n",
    "    @property\n",
    "    def board(self):\n",
    "        return self._board\n",
    "\n",
    "    @property\n",
    "    def game_status(self):\n",
    "        return self._game_status\n",
    "\n",
    "    @property\n",
    "    def current_player(self):\n",
    "        return self._current_player\n",
    "\n",
    "    @property\n",
    "    def round_nb(self):\n",
    "        return self._rounds_nb\n",
    "\n",
    "    def winner(self):\n",
    "        if self.game_status != GameStatus.ENDED:\n",
    "            return None\n",
    "        return self.other_player(self.current_player)\n",
    "\n",
    "    @staticmethod\n",
    "    def other_player(player):\n",
    "        if player == Pawn.WHITE:\n",
    "            return Pawn.BLACK\n",
    "        elif player == Pawn.BLACK:\n",
    "            return Pawn.WHITE\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_move(board, i, j, player):\n",
    "        m = len(board)\n",
    "        n = len(board[0]) if m > 0 else 0\n",
    "        if i < 0 or i >= m or j < 0 or j >= n:\n",
    "            return False\n",
    "        if board[i][j] != Clobber.other_player(player):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def can_clobber(board, i, j):\n",
    "        player = board[i][j]\n",
    "        neighbor_positions = [\n",
    "            (i - 1, j),\n",
    "            (i + 1, j),\n",
    "            (i, j - 1),\n",
    "            (i, j + 1)\n",
    "        ]\n",
    "        for ni, nj in neighbor_positions:\n",
    "            if Clobber.validate_move(board, ni, nj, player):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def game_ended(board):\n",
    "        for i in range(len(board)):\n",
    "            for j in range(len(board[i])):\n",
    "                field = board[i][j]\n",
    "                if field in (Pawn.BLACK, Pawn.WHITE):\n",
    "                    if Clobber.can_clobber(board, i, j):\n",
    "                        return False\n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def neighbor_moves(i, j):\n",
    "        return [\n",
    "            (i-1, j),\n",
    "            (i+1, j),\n",
    "            (i, j-1),\n",
    "            (i, j+1)\n",
    "        ]\n",
    "\n",
    "    def move(self, i, j, direction):\n",
    "        chosen_pawn = self.board[i][j]\n",
    "        if chosen_pawn != self._current_player:\n",
    "            raise WrongTurnException\n",
    "        match direction:\n",
    "            case Direction.UP:\n",
    "                move_i = -1\n",
    "                move_j = 0\n",
    "            case Direction.DOWN:\n",
    "                move_i = 1\n",
    "                move_j = 0\n",
    "            case Direction.RIGHT:\n",
    "                move_i = 0\n",
    "                move_j = 1\n",
    "            case Direction.LEFT:\n",
    "                move_i = 0\n",
    "                move_j = -1\n",
    "            case _:\n",
    "                raise WrongDirectionException\n",
    "        next_i = i+move_i\n",
    "        next_j = j+move_j\n",
    "        if not self.validate_move(self.board, next_i, next_j, self._current_player):\n",
    "            raise InvalidMoveException\n",
    "\n",
    "        self.board[i][j] = Pawn.EMPTY\n",
    "        self.board[next_i][next_j] = self._current_player\n",
    "        self._current_player = self.other_player(self.current_player)\n",
    "\n",
    "        self._rounds_nb += 1\n",
    "        self._game_status = GameStatus.IN_PROGRESS\n",
    "        if self.game_ended(self.board):\n",
    "            self._game_status = GameStatus.ENDED\n",
    "\n",
    "    def print(self, field_names=False):\n",
    "        self.print_board(self.board, field_names)\n",
    "\n",
    "    @staticmethod\n",
    "    def print_board(board, field_names=False):\n",
    "        n = len(board[0])\n",
    "        m = len(board)\n",
    "        if field_names:\n",
    "            print(end='    ')\n",
    "            print('  '.join((chr(letter) for letter in range(ord('A'), ord('A')+n))))\n",
    "            print(end='    ')\n",
    "            print('  '.join(('_' for _ in range(n))))\n",
    "        for i in range(len(board)):\n",
    "            row = board[i]\n",
    "            if field_names:\n",
    "                print(f'{m-i}|', end='  ')\n",
    "            print('  '.join((str(v) for v in row)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej znajdują się klasy wyjątków, używane w powyższej implementacji gry Clobber do obsłużenia sytuacji wyjątkowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:45:48.324388Z",
     "start_time": "2025-05-29T20:45:48.322373Z"
    }
   },
   "outputs": [],
   "source": [
    "class WrongTurnException(Exception):\n",
    "    pass\n",
    "\n",
    "class WrongDirectionException(Exception):\n",
    "    pass\n",
    "\n",
    "class InvalidMoveException(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementacja heurystyk\n",
    "### Dostępne podstawowe heurystyki:\n",
    "1. `active_pawns_heuristics` - zlicza pionki gracza oraz przeciwnika, które mają możliwość zaatakowania innych i zwraca różnicę między nimi (nagradza za aktywne pionki)\n",
    "2. `center_occupying_heuristics` - tworzy macierz wag pól na planszy, zlicza sumę punktów gracza i przeciwnika i zwraca różnicę między nimi (nagradza za zdobywanie centrum)\n",
    "3. `pawns_accumulations_heuristics` - zlicza \"wyspy\" (sąsiadujące grupy pionków) gracza i przeciwnika i zwraca różnicę między nimi (nagradza za nierozpraszanie się na planszy)\n",
    "\n",
    "Poza powyższymi zdefiniowane również zostały heurystyki adaptacyjne, powstałe w wyniku adaptacyjnego wyboru z powyższych heurystyk w zależności od stanu gry\n",
    "### Dostępne rozszerzone heurystyki:\n",
    "1. 'first_center_then_aggressive': - w początkowej fazie gry, strategia skupia się na zdobyciu centrum, później nagradza za aktywne pionki\n",
    "2. 'group_then_fight': group_then_fight, - na początku gry strategia skupia się na zgrupowaniu pionków, później na ataku\n",
    "3. 'take_middle_stay_in_group': take_middle_stay_in_group, - strategia grupuje pionki w centrum i pilnuje aby się nie rozchodziły"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:45:48.342304Z",
     "start_time": "2025-05-29T20:45:48.334341Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "\n",
    "def active_pawns_heuristics(board: Board, maximizing_player: Pawn) -> int:\n",
    "    max_active = 0\n",
    "    min_active = 0\n",
    "    for i, row in enumerate(board):\n",
    "        for j, pawn in enumerate(row):\n",
    "            if pawn == Pawn.EMPTY:\n",
    "                continue\n",
    "            if Clobber.can_clobber(board, i, j):\n",
    "                if pawn == maximizing_player:\n",
    "                    max_active += 1\n",
    "                else:\n",
    "                    min_active += 1\n",
    "    return max_active - min_active\n",
    "\n",
    "\n",
    "def center_occupying_heuristics(board: Board, maximizing_player: Pawn) -> int:\n",
    "    m = len(board)\n",
    "    n = len(board[0])\n",
    "    weights = generate_weight_grid(n, m)\n",
    "    max_score = 0\n",
    "    min_score = 0\n",
    "    for i, row in enumerate(board):\n",
    "        for j, pawn in enumerate(row):\n",
    "            if pawn == Pawn.EMPTY:\n",
    "                continue\n",
    "            weight = weights[i][j]\n",
    "            if pawn == maximizing_player:\n",
    "                max_score += weight\n",
    "            else:\n",
    "                min_score += weight\n",
    "    return max_score - min_score\n",
    "\n",
    "@lru_cache\n",
    "def generate_weight_grid(n: int, m: int) -> list[list[int]]:\n",
    "    def calculate_weight(i, j, rows, cols):\n",
    "        dist_i = min(i, rows - 1 - i)\n",
    "        dist_j = min(j, cols - 1 - j)\n",
    "\n",
    "        base = dist_i + dist_j\n",
    "        bonus = min(dist_i, dist_j)\n",
    "\n",
    "        return base + bonus\n",
    "\n",
    "    return [[calculate_weight(i, j, rows=m, cols=n) for j in range(n)] for i in range(m)]\n",
    "\n",
    "\n",
    "def pawns_accumulations_heuristics(board: Board, maximizing_player: Pawn) -> int:\n",
    "    max_islands = 0\n",
    "    min_islands = 0\n",
    "    visited = set()\n",
    "    for i, row in enumerate(board):\n",
    "        for j, pawn in enumerate(row):\n",
    "            if (i, j) in visited or pawn == Pawn.EMPTY:\n",
    "                continue\n",
    "            stack = [(i, j)]\n",
    "            while stack:\n",
    "                x, y = stack.pop()\n",
    "                if (x, y) in visited:\n",
    "                    continue\n",
    "                visited.add((x, y))\n",
    "                for dx, dy in [(0,1), (1,0), (0,-1), (-1,0)]:\n",
    "                    nx, ny = x+dx, y+dy\n",
    "                    if 0 <= nx < len(board) and 0 <= ny < len(board[0]):\n",
    "                        if board[nx][ny] == pawn and (nx, ny) not in visited:\n",
    "                            stack.append((nx, ny))\n",
    "            if pawn == maximizing_player:\n",
    "                max_islands += 1\n",
    "            else:\n",
    "                min_islands += 1\n",
    "    return min_islands - max_islands\n",
    "\n",
    "\n",
    "def first_center_then_aggressive(board: Board, player: Pawn) -> float:\n",
    "    pawns_left_coeff = pawns_left_coefficient(board, player)\n",
    "    if pawns_left_coeff >= 0.6:\n",
    "        return center_occupying_heuristics(board, player)\n",
    "    elif pawns_left_coeff >= 0.4:\n",
    "        return active_pawns_heuristics(board, player) * 0.7 + center_occupying_heuristics(board, player) * 0.3\n",
    "    else:\n",
    "        return active_pawns_heuristics(board, player)\n",
    "\n",
    "def group_then_fight(board: Board, player: Pawn) -> float:\n",
    "    pawns_left_coeff = pawns_left_coefficient(board, player)\n",
    "    if pawns_left_coeff >= 0.6:\n",
    "        return pawns_accumulations_heuristics(board, player)\n",
    "    elif pawns_left_coeff >= 0.4:\n",
    "        return pawns_accumulations_heuristics(board, player) * 0.4 + active_pawns_heuristics(board, player) * 0.6\n",
    "    else:\n",
    "        return active_pawns_heuristics(board, player)\n",
    "\n",
    "def take_middle_stay_in_group(board: Board, player: Pawn) -> float:\n",
    "    pawns_left_coeff = pawns_left_coefficient(board, player)\n",
    "    if pawns_left_coeff >= 0.6:\n",
    "        return center_occupying_heuristics(board, player)\n",
    "    elif pawns_left_coeff >= 0.4:\n",
    "        return center_occupying_heuristics(board, player) * 0.5 + pawns_accumulations_heuristics(board, player) * 0.5\n",
    "    else:\n",
    "        return pawns_accumulations_heuristics(board, player)\n",
    "\n",
    "def pawns_left_coefficient(board: Board, player: Pawn) -> float:\n",
    "    initial_pawns = len(board) * len(board[0]) / 2\n",
    "    count = 0\n",
    "    for row in board:\n",
    "        for pawn in row:\n",
    "            if pawn == player:\n",
    "                count += 1\n",
    "    return count / initial_pawns\n",
    "\n",
    "\n",
    "HEURISTIC_MAP = {\n",
    "    'active': active_pawns_heuristics,\n",
    "    'center': center_occupying_heuristics,\n",
    "    'accumulation': pawns_accumulations_heuristics\n",
    "}\n",
    "\n",
    "HEURISTIC_MAP_EXTENDED = {\n",
    "    'first_center_then_aggressive': first_center_then_aggressive,\n",
    "    'group_then_fight': group_then_fight,\n",
    "    'take_middle_stay_in_group': take_middle_stay_in_group,\n",
    "    **HEURISTIC_MAP\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implementacja algorytmów Minimax i Alpha-Beta\n",
    "### Kluczowe elementy:\n",
    "- **Reprezentacja stanu gry** - klasa ClobberState odpowiada za przechowywanie obecnego stanu gry. Przechowuje ona planszę, oraz informację o graczu wykonującym ruch. Udostępnia metodę pozwalającą wykonać ruch - metoda ta zwraca kolejny obiekt ClobberState (stan gry po wykonaniu ruchu)\n",
    "- **Generowanie możliwych ruchów** - wyżej wspomniana klasa udostępnia również funkcję pozwlającą generować wszystkie możliwe ruchu w danym stanie gry (jest to niezbędny element dla algorytmu *minimax*\n",
    "- **Implementacja Minimax** - implementacja algorytmu minimax dla gry Clobber. Przyjmuje jako argumenty stan gry, głębokość, maksymalizowanego gracza, heurystykę oraz statystyki. Algorytm rekurencyjnie schodzi od korzenia drzewa w dół aż dojdzie do liści lub głębokość wyniesie 0. Wówczas liczona jest heurystyka dla danego poziomu i algorytm wracając do korzenia wybiera optymalną (wg. używanej heurystyki) ścieżkę. Przekazywany w dół drzewa atrybut *stats* pozwala na zliczanie odwiedzonych wierzchołków drzewa celem późniejszego logowania tej informacji.\n",
    "- **Implementacja Alpha-Beta z cięciami** - analogiczny algorytm do powyższego, z tym że przyjmuje dwa dodatkowe argumenty - alpha, beta, dzięki którym może odpowiednio wcześnie zakończyć przeglądanie fragmentu drzewa, które napewno nie jest optymalne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:45:48.360333Z",
     "start_time": "2025-05-29T20:45:48.351957Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Optional\n",
    "import time\n",
    "\n",
    "\n",
    "WINNING_VALUE = 1000\n",
    "\n",
    "\n",
    "class ClobberState:\n",
    "    def __init__(self, board: List[List[Pawn]], current_player: Pawn):\n",
    "        self.board = board\n",
    "        self.current_player = current_player\n",
    "        self._m = len(board)\n",
    "        self._n = len(board[0]) if self._m > 0 else 0\n",
    "\n",
    "    def get_possible_moves(self) -> List[Tuple[int, int, Direction]]:\n",
    "        moves = []\n",
    "        for i in range(self._m):\n",
    "            for j in range(self._n):\n",
    "                if self.board[i][j] == self.current_player:\n",
    "                    for direction in Direction:\n",
    "                        di, dj = 0, 0\n",
    "                        if direction == Direction.UP:\n",
    "                            di = -1\n",
    "                        elif direction == Direction.DOWN:\n",
    "                            di = 1\n",
    "                        elif direction == Direction.LEFT:\n",
    "                            dj = -1\n",
    "                        elif direction == Direction.RIGHT:\n",
    "                            dj = 1\n",
    "                        ni, nj = i + di, j + dj\n",
    "                        if 0 <= ni < self._m and 0 <= nj < self._n:\n",
    "                            if self.board[ni][nj] == Clobber.other_player(self.current_player):\n",
    "                                moves.append((i, j, direction))\n",
    "        return moves\n",
    "\n",
    "    def make_move(self, move: Tuple[int, int, Direction]) -> 'ClobberState':\n",
    "        i, j, direction = move\n",
    "        new_board = [row.copy() for row in self.board]\n",
    "\n",
    "        di, dj = 0, 0\n",
    "        if direction == Direction.UP:\n",
    "            di = -1\n",
    "        elif direction == Direction.DOWN:\n",
    "            di = 1\n",
    "        elif direction == Direction.LEFT:\n",
    "            dj = -1\n",
    "        elif direction == Direction.RIGHT:\n",
    "            dj = 1\n",
    "\n",
    "        ni, nj = i + di, j + dj\n",
    "        new_board[i][j] = Pawn.EMPTY\n",
    "        new_board[ni][nj] = self.current_player\n",
    "        next_player = Clobber.other_player(self.current_player)\n",
    "        return ClobberState(new_board, next_player)\n",
    "\n",
    "    def is_terminal(self) -> bool:\n",
    "        return len(self.get_possible_moves()) == 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"\\n\".join(\" \".join(p.value for p in row) for row in self.board)\n",
    "\n",
    "\n",
    "def utility(state: ClobberState, maximizing_player: Pawn) -> int:\n",
    "    winner = Clobber.other_player(state.current_player)\n",
    "    return WINNING_VALUE if winner == maximizing_player else -WINNING_VALUE\n",
    "\n",
    "\n",
    "def minimax(state: ClobberState, depth: int, maximizing_player: Pawn, heuristic, stats: Dict) -> int:\n",
    "    stats['nodes'] += 1\n",
    "    if depth == 0 or state.is_terminal():\n",
    "        if state.is_terminal():\n",
    "            return utility(state, maximizing_player)\n",
    "        return heuristic(state.board, maximizing_player)\n",
    "\n",
    "    if state.current_player == maximizing_player:\n",
    "        value = -float('inf')\n",
    "        for move in state.get_possible_moves():\n",
    "            new_state = state.make_move(move)\n",
    "            value = max(value, minimax(new_state, depth - 1, maximizing_player, heuristic, stats))\n",
    "        return value\n",
    "    else:\n",
    "        value = float('inf')\n",
    "        for move in state.get_possible_moves():\n",
    "            new_state = state.make_move(move)\n",
    "            value = min(value, minimax(new_state, depth - 1, maximizing_player, heuristic, stats))\n",
    "        return value\n",
    "\n",
    "\n",
    "def alphabeta(state: ClobberState, depth: int, alpha: float, beta: float,\n",
    "              maximizing_player: Pawn, heuristic, stats: Dict) -> int:\n",
    "    stats['nodes'] += 1\n",
    "    if depth == 0 or state.is_terminal():\n",
    "        if state.is_terminal():\n",
    "            return utility(state, maximizing_player)\n",
    "        return heuristic(state.board, maximizing_player)\n",
    "\n",
    "    if state.current_player == maximizing_player:\n",
    "        value = -float('inf')\n",
    "        for move in state.get_possible_moves():\n",
    "            new_state = state.make_move(move)\n",
    "            value = max(value, alphabeta(new_state, depth - 1, alpha, beta, maximizing_player, heuristic, stats))\n",
    "            alpha = max(alpha, value)\n",
    "            if value >= beta:\n",
    "                break\n",
    "        return value\n",
    "    else:\n",
    "        value = float('inf')\n",
    "        for move in state.get_possible_moves():\n",
    "            new_state = state.make_move(move)\n",
    "            value = min(value, alphabeta(new_state, depth - 1, alpha, beta, maximizing_player, heuristic, stats))\n",
    "            beta = min(beta, value)\n",
    "            if value <= alpha:\n",
    "                break\n",
    "        return value\n",
    "\n",
    "\n",
    "def find_best_move(state: ClobberState, depth: int, player: Pawn, heuristic,\n",
    "                   use_alpha_beta: bool, stats: Dict) -> Tuple[Optional[Tuple[int, int, Direction]], float, int, float]:\n",
    "    moves = state.get_possible_moves()\n",
    "    if not moves:\n",
    "        return None, 0, 0, 0.0\n",
    "\n",
    "    is_maximizing = (player == state.current_player)\n",
    "\n",
    "    best_value = -float('inf') if is_maximizing else float('inf')\n",
    "    best_move = None\n",
    "    alpha = -float('inf')\n",
    "    beta = float('inf')\n",
    "\n",
    "    start_time = time.time()\n",
    "    stats['nodes'] = 0\n",
    "\n",
    "    for move in moves:\n",
    "        new_state = state.make_move(move)\n",
    "\n",
    "        if use_alpha_beta:\n",
    "            value = alphabeta(\n",
    "                new_state,\n",
    "                depth - 1,\n",
    "                alpha,\n",
    "                beta,\n",
    "                player,\n",
    "                heuristic,\n",
    "                stats\n",
    "            )\n",
    "        else:\n",
    "            value = minimax(\n",
    "                new_state,\n",
    "                depth - 1,\n",
    "                player,\n",
    "                heuristic,\n",
    "                stats\n",
    "            )\n",
    "\n",
    "        if is_maximizing:\n",
    "            if value > best_value:\n",
    "                best_value = value\n",
    "                best_move = move\n",
    "                alpha = max(alpha, best_value)\n",
    "        else:\n",
    "            if value < best_value:\n",
    "                best_value = value\n",
    "                best_move = move\n",
    "                beta = min(beta, best_value)\n",
    "\n",
    "        # alpha-beta pruning\n",
    "        if use_alpha_beta and alpha >= beta:\n",
    "            break\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    return best_move, best_value, stats['nodes'], elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Główny program AI\n",
    "### Funkcjonalności:\n",
    "- Tryb podstawowy: obaj gracze używają tej samej strategii (atrybuty depth i heuristics)\n",
    "- Tryb rozszerzony: możliwość definiowania różnych strategii dla każdego gracza (atrybuty [black/white]_depth i [black/white]_heuristics)\n",
    "- Wsparcie dla cięć alfa-beta (możliwe również wyłączenie tej opcji)\n",
    "- Szczegółowe logowanie przebiegu gry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:45:48.367571Z",
     "start_time": "2025-05-29T20:45:48.363435Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_clobber_ai(\n",
    "    m=5,\n",
    "    n=6,\n",
    "    depth=3,\n",
    "    heuristic='center',\n",
    "    alpha_beta=True,\n",
    "    black_heuristic=None,\n",
    "    black_depth=None,\n",
    "    white_heuristic=None,\n",
    "    white_depth=None\n",
    "):\n",
    "    clobber = Clobber(n=n, m=m)\n",
    "    board = clobber.board\n",
    "    state = ClobberState(board, Pawn.BLACK)\n",
    "    round_count = 0\n",
    "    total_nodes = 0\n",
    "    total_time = 0.0\n",
    "\n",
    "    extended_mode = any([black_heuristic, white_heuristic, black_depth is not None, white_depth is not None])\n",
    "\n",
    "    if extended_mode:\n",
    "        # extended configuration\n",
    "        if not all([black_heuristic, white_heuristic,\n",
    "                    black_depth is not None, white_depth is not None]):\n",
    "            raise ValueError(\n",
    "                \"Extended mode requires all of: black_heuristic, black_depth, white_heuristic, white_depth\"\n",
    "            )\n",
    "\n",
    "        black_heuristic_func = HEURISTIC_MAP_EXTENDED.get(black_heuristic)\n",
    "        white_heuristic_func = HEURISTIC_MAP_EXTENDED.get(white_heuristic)\n",
    "        if black_heuristic_func is None or white_heuristic_func is None:\n",
    "            raise ValueError(f\"Invalid heuristic. Available: {list(HEURISTIC_MAP_EXTENDED.keys())}\")\n",
    "\n",
    "    else:\n",
    "        # basic configuration\n",
    "        if depth is None or heuristic is None:\n",
    "            raise ValueError(\"Basic mode requires 'depth' and 'heuristic'\")\n",
    "\n",
    "        heuristic_func = HEURISTIC_MAP_EXTENDED.get(heuristic)\n",
    "        if heuristic_func is None:\n",
    "            raise ValueError(f\"Invalid heuristic. Available: {list(HEURISTIC_MAP_EXTENDED.keys())}\")\n",
    "\n",
    "        black_heuristic_func = white_heuristic_func = heuristic_func\n",
    "        black_depth = white_depth = depth\n",
    "\n",
    "    use_alpha_beta = alpha_beta\n",
    "\n",
    "    # MAIN LOOP\n",
    "    stats = {'nodes': 0}\n",
    "    while not state.is_terminal():\n",
    "        current_player = state.current_player\n",
    "        if current_player == Pawn.BLACK:\n",
    "            curr_depth = black_depth\n",
    "            curr_heuristic = black_heuristic_func\n",
    "            player_name = \"BLACK\"\n",
    "        else:\n",
    "            curr_depth = white_depth\n",
    "            curr_heuristic = white_heuristic_func\n",
    "            player_name = \"WHITE\"\n",
    "\n",
    "        move, value, nodes, elapsed = find_best_move(\n",
    "            state, curr_depth, current_player, curr_heuristic, use_alpha_beta, stats\n",
    "        )\n",
    "\n",
    "        if move is None:\n",
    "            print(f\"{player_name} has no valid moves!\")\n",
    "            break\n",
    "\n",
    "        print(f\"Round {round_count + 1}, {player_name} move: {move}, value: {value:.2f}, nodes: {nodes}, time: {elapsed:.4f}s\")\n",
    "        state = state.make_move(move)\n",
    "        round_count += 1\n",
    "        total_nodes += nodes\n",
    "        total_time += elapsed\n",
    "\n",
    "    # end result\n",
    "    print(\"Final board:\")\n",
    "    Clobber.print_board(state.board)\n",
    "\n",
    "    winner = \"NONE\"\n",
    "    if state.is_terminal():\n",
    "        winner = \"BLACK\" if state.current_player == Pawn.WHITE else \"WHITE\"\n",
    "    print(f\"\\nRounds: {round_count}, Winner: {winner}\")\n",
    "    print(f\"Total nodes: {total_nodes}, Total time: {total_time:.4f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testowanie i wyniki\n",
    "### Przykładowe uruchomienia\n",
    "\n",
    "**Tryb podstawowy:**\n",
    "```\n",
    "run_clobber_ai(\n",
    "    n=5,\n",
    "    m=6,\n",
    "    depth=2,\n",
    "    heuristic='active',\n",
    "    alpha_beta=True\n",
    ")\n",
    "```\n",
    "\n",
    "**Tryb rozszerzony:**\n",
    "```\n",
    "run_clobber_ai(\n",
    "    n=5,\n",
    "    m=6,\n",
    "    depth=3,\n",
    "    black_depth=3,\n",
    "    black_heuristic='adaptive1',\n",
    "    white_depth=2,\n",
    "    white_heuristic='accumulation',\n",
    "    alpha_beta=True\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:45:48.434001Z",
     "start_time": "2025-05-29T20:45:48.377535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1, BLACK move: (0, 1, <Direction.DOWN: 2>), value: 0.00, nodes: 140, time: 0.0064s\n",
      "Round 2, WHITE move: (2, 0, <Direction.DOWN: 2>), value: 0.00, nodes: 174, time: 0.0071s\n",
      "Round 3, BLACK move: (0, 3, <Direction.DOWN: 2>), value: 0.00, nodes: 107, time: 0.0040s\n",
      "Round 4, WHITE move: (0, 0, <Direction.DOWN: 2>), value: -1.00, nodes: 154, time: 0.0057s\n",
      "Round 5, BLACK move: (1, 1, <Direction.LEFT: 4>), value: 0.00, nodes: 99, time: 0.0035s\n",
      "Round 6, WHITE move: (0, 2, <Direction.DOWN: 2>), value: -1.00, nodes: 125, time: 0.0043s\n",
      "Round 7, BLACK move: (1, 3, <Direction.LEFT: 4>), value: 0.00, nodes: 89, time: 0.0029s\n",
      "Round 8, WHITE move: (0, 4, <Direction.DOWN: 2>), value: -1.00, nodes: 92, time: 0.0029s\n",
      "Round 9, BLACK move: (1, 2, <Direction.DOWN: 2>), value: 0.00, nodes: 99, time: 0.0031s\n",
      "Round 10, WHITE move: (2, 4, <Direction.DOWN: 2>), value: -1.00, nodes: 82, time: 0.0025s\n",
      "Round 11, BLACK move: (2, 1, <Direction.DOWN: 2>), value: 0.00, nodes: 73, time: 0.0021s\n",
      "Round 12, WHITE move: (3, 0, <Direction.RIGHT: 3>), value: 0.00, nodes: 56, time: 0.0015s\n",
      "Round 13, BLACK move: (4, 3, <Direction.LEFT: 4>), value: 0.00, nodes: 82, time: 0.0022s\n",
      "Round 14, WHITE move: (3, 3, <Direction.UP: 1>), value: -1.00, nodes: 86, time: 0.0023s\n",
      "Round 15, BLACK move: (3, 2, <Direction.LEFT: 4>), value: 0.00, nodes: 39, time: 0.0009s\n",
      "Round 16, WHITE move: (5, 1, <Direction.LEFT: 4>), value: 0.00, nodes: 42, time: 0.0010s\n",
      "Round 17, BLACK move: (2, 2, <Direction.RIGHT: 3>), value: 0.00, nodes: 13, time: 0.0003s\n",
      "Round 18, WHITE move: (4, 4, <Direction.DOWN: 2>), value: 0.00, nodes: 13, time: 0.0003s\n",
      "Round 19, BLACK move: (4, 1, <Direction.LEFT: 4>), value: 0.00, nodes: 6, time: 0.0001s\n",
      "Round 20, WHITE move: (5, 0, <Direction.UP: 1>), value: 0.00, nodes: 4, time: 0.0001s\n",
      "Round 21, BLACK move: (5, 2, <Direction.RIGHT: 3>), value: -1000.00, nodes: 2, time: 0.0000s\n",
      "Round 22, WHITE move: (5, 4, <Direction.LEFT: 4>), value: 1000.00, nodes: 1, time: 0.0000s\n",
      "Final board:\n",
      "_  _  _  _  _\n",
      "B  _  _  _  W\n",
      "_  _  _  B  _\n",
      "_  B  _  _  W\n",
      "W  _  B  _  _\n",
      "_  _  _  W  _\n",
      "\n",
      "Rounds: 22, Winner: WHITE\n",
      "Total nodes: 1578, Total time: 0.0532s\n"
     ]
    }
   ],
   "source": [
    "run_clobber_ai(\n",
    "    n=5,\n",
    "    m=6,\n",
    "    depth=2,\n",
    "    heuristic='active',\n",
    "    alpha_beta=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:45:48.811430Z",
     "start_time": "2025-05-29T20:45:48.453629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1, BLACK move: (1, 2, <Direction.DOWN: 2>), value: 6.00, nodes: 6087, time: 0.1552s\n",
      "Round 2, WHITE move: (4, 2, <Direction.RIGHT: 3>), value: -1.00, nodes: 597, time: 0.0245s\n",
      "Round 3, BLACK move: (3, 0, <Direction.RIGHT: 3>), value: 12.00, nodes: 3141, time: 0.0748s\n",
      "Round 4, WHITE move: (0, 0, <Direction.DOWN: 2>), value: -1.00, nodes: 118, time: 0.0047s\n",
      "Round 5, BLACK move: (0, 1, <Direction.DOWN: 2>), value: 15.00, nodes: 1616, time: 0.0352s\n",
      "Round 6, WHITE move: (0, 2, <Direction.RIGHT: 3>), value: -1.00, nodes: 92, time: 0.0033s\n",
      "Round 7, BLACK move: (1, 4, <Direction.LEFT: 4>), value: 20.00, nodes: 757, time: 0.0160s\n",
      "Round 8, WHITE move: (2, 4, <Direction.LEFT: 4>), value: -1.00, nodes: 126, time: 0.0042s\n",
      "Round 9, BLACK move: (3, 4, <Direction.LEFT: 4>), value: 18.00, nodes: 440, time: 0.0086s\n",
      "Round 10, WHITE move: (2, 3, <Direction.DOWN: 2>), value: -1.00, nodes: 106, time: 0.0032s\n",
      "Round 11, BLACK move: (5, 4, <Direction.UP: 1>), value: 17.00, nodes: 316, time: 0.0057s\n",
      "Round 12, WHITE move: (4, 0, <Direction.RIGHT: 3>), value: 0.00, nodes: 74, time: 0.0020s\n",
      "Round 13, BLACK move: (4, 4, <Direction.LEFT: 4>), value: 5.20, nodes: 291, time: 0.0082s\n",
      "Round 14, WHITE move: (2, 0, <Direction.RIGHT: 3>), value: -1.00, nodes: 72, time: 0.0018s\n",
      "Round 15, BLACK move: (1, 1, <Direction.DOWN: 2>), value: 5.60, nodes: 155, time: 0.0039s\n",
      "Round 16, WHITE move: (3, 3, <Direction.DOWN: 2>), value: -1.00, nodes: 38, time: 0.0008s\n",
      "Round 17, BLACK move: (5, 0, <Direction.RIGHT: 3>), value: 4.80, nodes: 59, time: 0.0013s\n",
      "Round 18, WHITE move: (4, 1, <Direction.UP: 1>), value: -1.00, nodes: 13, time: 0.0003s\n",
      "Round 19, BLACK move: (1, 3, <Direction.UP: 1>), value: 0.00, nodes: 28, time: 0.0005s\n",
      "Round 20, WHITE move: (3, 1, <Direction.UP: 1>), value: 0.00, nodes: 12, time: 0.0002s\n",
      "Round 21, BLACK move: (0, 3, <Direction.RIGHT: 3>), value: 0.00, nodes: 13, time: 0.0002s\n",
      "Round 22, WHITE move: (2, 1, <Direction.RIGHT: 3>), value: 1.00, nodes: 5, time: 0.0001s\n",
      "Round 23, BLACK move: (3, 2, <Direction.UP: 1>), value: 1000.00, nodes: 6, time: 0.0001s\n",
      "Round 24, WHITE move: (5, 3, <Direction.LEFT: 4>), value: -1000.00, nodes: 2, time: 0.0000s\n",
      "Round 25, BLACK move: (5, 1, <Direction.RIGHT: 3>), value: 1000.00, nodes: 1, time: 0.0000s\n",
      "Final board:\n",
      "_  _  _  _  B\n",
      "W  _  _  _  _\n",
      "_  _  B  _  _\n",
      "_  _  _  _  _\n",
      "_  _  _  W  _\n",
      "_  _  B  _  _\n",
      "\n",
      "Rounds: 25, Winner: BLACK\n",
      "Total nodes: 14165, Total time: 0.3548s\n"
     ]
    }
   ],
   "source": [
    "run_clobber_ai(\n",
    "    n=5,\n",
    "    m=6,\n",
    "    depth=3,\n",
    "    black_depth=3,\n",
    "    black_heuristic='first_center_then_aggressive',\n",
    "    white_depth=2,\n",
    "    white_heuristic='accumulation',\n",
    "    alpha_beta=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wnioski z testowania\n",
    "1. **Wpływ głębokości przeszukiwania:**\n",
    "    - Zwiększenie głębokości poprawia jakość ruchów\n",
    "    - Kosztem jest wzrost czasu obliczeń i liczby odwiedzonych węzłów\n",
    "2. **Skuteczność cięć alfa-beta:**\n",
    "    - Znacząca redukcja liczby odwiedzanych wierzchołków\n",
    "    - Przyspieszenie czasu wykonania algorytmu\n",
    "    - Możliwość zastosowania większego poziomu głębokości (dzieki skróconemu czasowi)\n",
    "3. **Nie zawsze wygrywa rozpoczynający grę** - nawet jeśli gra odbywa się z perspektywy jednego agenta, który dla obu stron wykorzystuje te same heurystyki i głębokości, nie zawsze wygrywa gracz czarny, który z racji, że zaczyna - ma większą przewagę. Wynika to najprawdopodobniej z niedoskonałości używanych heurystyk i niskiego poziomu głębokości. Wspólnie dwa te czynniki mogą powodować wykonywanie ruchów prowadzących w większej perspektywie do przegranej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Podsumowanie i wnioski\n",
    "### Osiągnięte cele:\n",
    "1. Poprawna implementacja gry Clobber\n",
    "2. Zrealizowanie algorytmów Minimax i Alpha-Beta\n",
    "3. Implementacja różnych heurystyk oceny stanu gry (również adaptacyjnych)\n",
    "4. Wykonanie zarówno trybu podstawowego, jak i rozszerzonego\n",
    "\n",
    "### Napotkane problemy:\n",
    "1. **Nieznajomość gry** - w związku z tym, że wcześniej nie miałem do czynienia z grą Clobber, na początku musiałem zrozumieć jej zasady. Jednak samo zrozumienie zasad to niestety za mało, gdyż zadanie wymagało utworzenia odpowiednich heurystyk odzwierciedlających stan gry - wymagała to większego zgłębienia strategii w grze (co również nie było łatwym zadaniem biorąc pod uwagę, że ciężko znaleźć nawet jakiekolwiek źródła na internecie, które by cokolwiek o tej grze i strategii z nią związanych wspominały.\n",
    "   \n",
    "2. **Tworzenie heurystyk** - nawet po zapoznaniu sie z grą, ze względu na jej specyfikę ciężko było wymyślić jakiekolwiek sensowne heurystyki. Chwilowe zapoznanie się z grą to zdecydowanie za mało na wymyślenie czegoś sensownego, tym bardziej, że gra ma bardzo nietypowe zasady, powodujące np. że zawsze liczba pionków obu graczy jest sobie równa lub różni się o 1, przez co dużo potencjalnych heurystyk związanych z ilością pionów, jakie możnaby zastosować w innych, podobnych grach tutaj się nie nadawały.\n",
    "   \n",
    "3. **Poprawność algorytmu** - algorytm minimax oraz cięcie alfa-beta mimo tego, że nie są algorytmami mocno skomplikowanymi, z racji implementacji ich po raz pierwszy, przysporzyły sporo problemów, zarówno natury omyłkowej (małych błędów w kodzie, literówek), jak i poważniejszych, wynikających z nieprawidłowego zrozumienia działania algorytmu, które zmuszały do poważnych zmian w implementacji.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Wykorzystane biblioteki\n",
    "1. **enum** - biblioteka pozwalająca na implementację klasy enumeratora w pythonie. W moim przypadku wykorzystana celem utworzenia klas takich jak Direction, Pawn, czy GameStatus\n",
    "\n",
    "2. **functools** - biblioteka z funkcjami wyższego rzędu. Wykorzystałem z niej funkcję lru_cache, dzięki której mogłem cache'ować dane w funkcji generującej macierz wag (do heurystyki), która była często wywoływana z tymi samymi parametrami.\n",
    "\n",
    "3. **typing** - biblioteka zawierająca typy danych w pythonie. Używana celem jawnego podawania typów (zwiększenie estetyki i przejrzystości kodu) a także tworzenia własnych aliasów, np. Board\n",
    "\n",
    "4. **time** - biblioteka zawierająca funkcje związane z czasem. Użyta do logowania czasu trwania poszczególnych etapów liczenia w algorytmach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Źródła\n",
    "1. https://www.youtube.com/watch?v=zahxNZYvvj8 - film przedstawiający rozgrywkę w Clobbera\n",
    "2. https://www.iggamecenter.com/en/rules/clobber - podstawowe zasady Clobbera"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
